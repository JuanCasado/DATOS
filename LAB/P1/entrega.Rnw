
\documentclass [a4paper] {article}
\usepackage[utf8]{inputenc}
\title{Ciencia de datos, práctica 1}
\author{Juan Casado Ballesteros}
\begin{document}
\maketitle

\begin{abstract}
En esta práctica vamos a realizar tres análisis estadísticos, 
en los dos primeros utilizaremos las funciones propias de R sobre los datos proporcionados por el profesor en los formatos .txt para el primero y .sav para el segundo.
En el tercer análisis hemos programado nosotros mismos nuestras propias funciones. 
Como datos hemos elegido un .csv que contiene información sobre el alquiler en la Ciudad de Nueva York.
Intentaremos para este tercer análisis realizar un estudio crítico que nos permita llegar a conocer los datos con los que estamos trabajando.

Las dos últimas secciones del documento hacen referencia a dos listados de funciones, 
el primero de las funciones de R que deberíamos conocer y el segundo de las creadas por nosotros junto a su implementación.
\end{abstract}

\newpage
\tableofcontents
\newpage

<<cargar_funciones_credas, echo=FALSE>>=
source("init.R")
@

%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Primer análisis satelites menores de urano.txt}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Comenzamos leyendo los datos del archivo .txt ya que dicho archivo lo hemos escrito con la sintaxis que read.table espera 
no tendremos que utilizar ningún parámetro adicional para configurar la lectura de los datos.
<<cargarDatosIniciales>>=
satelites <- read.table("./satelites.txt")
@

\subsection{Frecuencias}
\subsubsection{Frecuencia Absoluta}
Primero calcularemos la frecuencia absoluta de los datos, que es el número de apariciones de cada uno de ellos.
Vemos que todos los valores aparecen solo una vez excepto 20 que está dos veces.

<<frecuencia_absoluta_satelites>>=
frecuencia_absoluta<-table(satelites$radio)
@
\begin{center}
<<frecuencia_absoluta_satelites_plot, echo=FALSE, fig=TRUE>>=
plot(frecuencia_absoluta, type="h", xlab="Radios de los satélites menores de Urano")
@
\end{center}

La moda es el dato cuya frecuencia absolutaes mayor.
<<moda_satelites>>=
datos_ordenados=sort(frecuencia_absoluta,TRUE)
moda_ <- as.numeric(rownames(as.matrix(datos_ordenados))[1])
moda_
@

\subsubsection{Frecuencia Absoluta Acumulada}
Ahora calcularemos la frecuencia absoluta acumulada que es la crecuencia absoluta de cada dato sumada con la de todos los menores a él.
La frecuencia absoluta se va incrementadndo de forma uniforme, de uno en uno, hasta llegar a 20 que aumenta en dos tal y comno se esperaba.

Cuando utilizamos la función textbf{cumsum}, cuya función es acumular las frecuencias, es recomendable aplicar as.table para que los datos sigan en el formato de tabla.
Esto nos permitirá luego mostrarlos en la gráfica sin problemas.

<<frecuencia_absoluta_acumulada_satelites>>=
frecuencia_absoluta_acumulada<-as.table(cumsum(frecuencia_absoluta))
@
\begin{center}
<<frecuencia_absoluta_acumulada_satelites_plot, fig=TRUE, echo=FALSE>>=
plot(frecuencia_absoluta_acumulada, type="h", xlab="Radios de los satélites menores de Urano")
@
\end{center}

\newpage
\subsubsection{Frecuencia Relativa}
La frecuencia relativa que es la frecuencia absoluta dividida por la cantidad de datos que hay.
La suma de las frecuencias relativas debe dar 1 como resultado lo cual comprobamos.
La frecuncia relativa por si sola aporta más información que la frecuencia absoluta pues está normalizada entre dos valores conocidos 0 y 1.
Para que la frecuencia absoluta nos aporte la misma información necesitamos conocer la cantidad de valores que tenemos para poder enmarcar el dato en su contexto.

<<frecuencia_relativa_satelites>>=
frecuencia_relativa <- (function(data) table(data)/length(data))(satelites$radio)
sum(frecuencia_relativa)
@
\begin{center}
<<frecuencia_relativa_satelites_plot,fig=TRUE, echo=FALSE>>=
plot(frecuencia_relativa, type="h", xlab="Radios de los satélites menores de Urano")
@
\end{center}

\newpage
\subsubsection{Frecuencia Relativa Acumulada}
La frecuencia relativa acumulada que es la suma de la frecuencia relativa de cada valor con la de los menores a él.

<<frecuencia_relativa_acumulada_satelites>>=
frecuencia_relativa_acumulada <- as.table(cumsum(frecuencia_relativa))
@
\begin{center}
<<frecuencia_relativa_acumulada_satelites_plot, fig=TRUE, echo=FALSE>>=
plot(frecuencia_relativa_acumulada, type="h", xlab="Radios de los satélites menores de Urano")
@
\end{center}

\newpage
\subsection{Valores representativos}
Calcularemos a continuación estadísticos cuya función es resumir los datos de los que disponemos.

\subsubsection{Media aritmética}
La media aritméticaconsite en una suma de los datos ponderada por la cantidad de estos.
Como podemos ver la media está ligeramente desplazada del centro del rango (29) siendo más próxima a radios de menor tamaño.

<<media_satelites>>=
media_ <- mean(satelites$radio)
media_
@

\subsubsection{Desviación típica}
La desviacion típica es pequeña lo que hace que la media sea una buen valor para representar a los datos.
Sabemos que la media es buena a partir de la desviacion típica obtenida utilizando el teorema de tchebychev vemos 
que los valores de todos los radios se los satélites quedan dentro del intervalo $[media-2 * desviación típica, media+2 * desviación típica]$ 
cuando como mínimo solo tendrían que estar el 75\%.

<<desviacion_tipica_satelites>>=
desviacion_tipica_ <- sd(satelites$radio)
desviacion_tipica_
@

Tchebychev para k=2, al menos el 75\% de los datos estarán dentro del rango $[media -2 * desviación típica, media +2 * desviación típica]$, 
para nuestro caso todos lo están.
<<>>=
c(media_-2*desviacion_tipica_, media_+2*desviacion_tipica_)
c(min(satelites$radio), max(satelites$radio))
@

\subsubsection{Varianza}
La varianza es el cuadrado de la desviación típica.

<<varianza_satelites>>=
varianza_ <- var(satelites$radio)
varianza_
@

\newpage
\subsection{Medidas de ordenanción}
\subsubsection{Cuartiles}

Los cuartiles son aquellos valores de modo que si los ordenáramos sobre un vector estarían en los índices situados en el 25, 50 y 75\%.
Hemos podico comprobar que R para calcular los cuartiles no lo hace exáctamente así si no que utiliza una distribución de probabilidad.
Cuando calculamos los cuartiles a mano con las fómulas de clase obtendremos valores distintos.

La mediana es el valor que está justo en el centro de los valores ordenados, segundo cuartil.
<<cuartiles_satelites>>=
cuartiles_ <- quantile(satelites$radio, prob=c(0, .25, .5, .75, 1))
cuartiles_
mediana_ <- median(satelites$radio) #cuartiles_[2]
mediana_
@

\begin{center}
<<cuartiles_satelites_plot, fig=TRUE, echo=FALSE>>=
boxplot(cuartiles_,horizontal=T,xlab="Radios de los satélites menores de Urano")
@
\end{center}

\subsubsection{Cuartil 54}
<<cuantil54_satelites>>=
cuantil54_ <- quantile(satelites$radio, prob=(.54))
cuantil54_
@

\subsection{Visualización}
Hemos encontrado de gran utilidad representar sobre una misma gráfica la frecuencia relativa, la media, la moda y la mediana.
Esta representación proporciona la mayoría de la información estadística que estamos calculando de un solo vistazo y ayuda a entender como se
distrubuyen los datos que manejamos y cómo se relacionan con los valores que pretenden representarlos.
\begin{center}
<<estadisticos_satelites_plot, fig=TRUE, echo=FALSE>>=
  plotFrecuencyData(satelites$radio, xlabel="Radios de los satélites menores de Urano")
@
\end{center}

\newpage
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Segundo análisis cardata .sav}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Para el segundo análisis estudiaremos los datos de la variable mpg que representa el consumo en millas por galón de un conjunto de automóbiles.
Comenzamos cargado los datos que deben ser preparados. 
Primero eliminamos el warning de Duplicated levels in factor y posteriormente eliminamos los valores nulos para poder realizar las operaciones correctamente.
<<cargar_datos_cardata>>=
cardata <- read.spss("./cardata.sav", use.value.labels = FALSE)$mpg
cardata <- cardata[!is.na(cardata)]
@

\subsection{Valores representativos}
\subsubsection{Media aritmética}
La media está muy próxima a la mediana (28.9) que a su ver está muy próxima al punto medio del rango de valores (31).
Podemos ver que está ligeramente desplazada hacia los valores menores sobre todo teniendo en cuenta que la moda es bastante elevada 
aunque esta muy poco representativa pues en general los valores se distribuyen de forma uniforme sobre el rango.
<<media_cardata>>=
media_ <- mean(cardata)
media_
@

\subsubsection{Desviación típica y varianza}
La desviación típica es baja, el radio de 2\*desviación típica del teorema de tchebychev cubre a gran parte de los valores, desde luego a más del 75\%.
Podemos decir que la media representa bien a los valores a pesar de que los que están en el extremo superior del rango queden un poco alejados de ella.
<<desviacion_tipica_cardata>>=
desviacion_tipica_ <- sd(cardata)
desviacion_tipica_
varianza_ <- var(cardata)
varianza_
@

\begin{center}
<<estadisticos_cardata_plot, fig=TRUE, echo=FALSE>>=
  plotFrecuencyData(cardata,xlabel="Consumo en (mpg)")
@
\end{center}

\newpage
\subsection{Medidas de ordenanción}
Podemos ver como los datos están repartidos de una forma bastante homogénea a lo largo de su rango de valores.
<<cuartiles_cardata>>=
cuartiles_ <- quantile(cardata, prob=c(0, .25, .5, .75, 1))
cuartiles_
mediana_ <- median(cardata) #cuartiles_[2]
mediana_
@
\begin{center}
<<ordenacion_cardata_plot, fig=TRUE, echo=FALSE>>=
boxplot(cuartiles_,horizontal=T,xlab="Consumo en (mpg)")
@
\end{center}

\newpage
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Tercer análisis del alquiler en Nueva York con AirBNB durante 2019 .csv}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

<<>>=
data <- read.csv("AB_NYC_2019.csv") #https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#AB_NYC_2019.csv
@

Haremos ahora un análisis de los datos del alquiler en la ciudad de Nueva York durante el año 2019 con la compañía AirBNB.
Los datos contienen las siguientes categorías:
<<get_info_BNB>>=
getInfo(data)
@
Comenzaremos por analizar el precio de los alquileres.
Para ello calcularemos la frecuencia relativa de los precios.
<<frecuencia_relativa_BNB>>=
frecuencia_relativa<-frecuenciaAbsoluta(data$price)
@
\begin{center}
<<frecuencia_relativa_BNB_plot, fig=TRUE, echo=FALSE>>=
plot(frecuencia_relativa, type="h")
@
\end{center}

Podemos observar que los precios están muy agrupados en la parte izquierda de la gráfica (precios bajos) con altos porcentajes de aparición,
no obstante aunque con una densidad mucho menor estos se alejan en gran medida llegando a alcanzar precios muy elevados pero con pocos porcentajes de aparición.

\begin{center}
<<estadisticos_BNB_plot, fig=TRUE, echo=FALSE>>=
plotFrecuencyData(data$price)
@
\end{center}

<<cuartiles_BNB>>=
v_cuartiles <- cuartiles(data$price)
@
\begin{center}
<<cuartiles_BNB_plot, fig=TRUE, echo=FALSE>>=
boxplot(v_cuartiles, horizontal=T)
@
\end{center}

Vemos que la media no es un valor representativo, su desviación típica es muy alta.
Podemos observar como la moda y la mediana en este caso parecen representar mejor a la mayoría de los datos.
Debido a esto decidimos que hacer el análisis de los precios para toda la ciudad no iba a aportarnos una visión representativa de los datos.
Decidimos ahora calcular el precio medio por cada barrio en vez de hacerlo sobre toda la ciudad a la vez.

<<estadisticos_barrios_BNB, echo=FALSE>>=
aggregate(data$price, list(data$neighbourhood_group), 
FUN=(function(barrio) c(media=mediaAritmetica(barrio),
                        desviacion_tipica=desviacionTipica(barrio),
                        mediana=mediana(barrio),
                        moda=moda(barrio))))
@
Valores sobre el total de los datos sin haber separado por barrios
<<estadisticos_BNB, echo=FALSE>>=
c(media=mediaAritmetica(data$price),
  desviacion_tipica=desviacionTipica(data$price),
  v_mediana=mediana(data$price),
  v_moda=moda(data$price))
@

Podemos ver que la varianza se ha reducido para más barrios de en los que ha aumentado.
En Bronx es en el barrio en el que tanto la varianza como la media es menor y 
Manhattan es en el que ambas son mayores.

Datos para Manhattan
\begin{center}
<<fig=TRUE>>=
manhattan_data = data$price[data$neighbourhood_group == "Manhattan"]
plotFrecuencyData(manhattan_data)
@
\end{center}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
boxplot(cuartiles(manhattan_data), horizontal=T)
@
\end{center}

Datos para Bronx
\begin{center}
<<fig=TRUE, echo=FALSE>>=
bronx_data <- data$price[data$neighbourhood_group == "Bronx"]
plotFrecuencyData(bronx_data)
@
\end{center}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
boxplot(cuartiles(bronx_data), horizontal=T)
@
\end{center}

Datos para Brooklyn
\begin{center}
<<fig=TRUE, echo=FALSE>>=
brooklyn_data <- data$price[data$neighbourhood_group == "Brooklyn"]
plotFrecuencyData(brooklyn_data)
@
\end{center}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
boxplot(cuartiles(brooklyn_data), horizontal=T)
@
\end{center}

Datos para Queens
\begin{center}
<<fig=TRUE, echo=FALSE>>=
queens_data <- data$price[data$neighbourhood_group == "Queens"]
plotFrecuencyData(queens_data)
@
\end{center}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
boxplot(cuartiles(queens_data), horizontal=T)
@
\end{center}

Datos para Staten Island
\begin{center}
<<fig=TRUE, echo=FALSE>>=
state_data <- data$price[data$neighbourhood_group == "Staten Island"]
plotFrecuencyData(state_data)
@
\end{center}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
boxplot(cuartiles(state_data), horizontal=T)
@
\end{center}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Guia en R para el análisis estadístico}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
<<cargar_funciones, echo=FALSE>>=
data <- read.table("./satelites.txt")$radio
@
\subsection{Frecuencias}
<<>>=
Frecuencia_absoluta <- table(data)
Frecuencia_absoluta_acumulada <- cumsum(frecuencia_absoluta)
Frecuencia_relativa <- (function(data) table(data)/length(data))(data)
Frecuencia_relativa_acumulada <- cumsum(frecuencia_relativa)
@
\subsection{Medidas representativas}
<<>>=
Media <- mean(data)
Desviacion_tipica <- sd(data)
Varianza <- var(data)
@
\subsection{Medidas de ordenación}
<<>>=
Mediana <- median(data)
Cuartiles <- quantile(data, prob=c(0, .25, .5, .75, 1))
Cuantil54 <- quantile(data, prob=(.54))
@

%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Funciones creadas}
%-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
\subsection{Frecuencias}
\subsubsection{Frecuencia Absoluta}
Obtenemos una lista ordenada de los valores únicos que componen nuestros datos.
La ferecuencia absoluta de cada valor único es la cantidad de veces que aparece.
<<frecuenciaAbsoluta>>=
frecuenciaAbsoluta
@
\subsubsection{Frecuencia Absoluta Acumulada}
Obtenemos una lista ordenada de los valores únicos que componen nuestros datos.
La ferecuencia absoluta acumulada de cada valor único es la cantidad de veces que aparece él sumada a la cantidad de veces que aparecen los valores menores a él.
<<frecuenciaAbsolutaAcumulada>>=
frecuenciaAbsolutaAcumulada
@
\subsubsection{Frecuencia Relativa}
Obtenemos una lista ordenada de los valores únicos que componen nuestros datos.
La ferecuencia relativa de cada valor es la cantidad de veces que aparece dividida por la cantidad de valores que hay.
Si sumamos todas las frecuencias relativas debemos obtener 1 como resultado.
<<frecuenciaRelativa>>=
frecuenciaRelativa
@
\subsubsection{Frecuencia Relativa Acumulada}
Obtenemos una lista ordenada de los valores únicos que componen nuestros datos.
La ferecuencia relativa acumulada de cada valor es la frecuencia absoluta de ese valor dividida entre la cantidad de valores que hay.
<<frecuenciaRelativaAcumulada>>=
frecuenciaRelativaAcumulada
@
\subsubsection{Moda}
Nos indica que dato tiene la mayor frecuencia absoluta.
<<moda>>=
moda
@

\subsection{Medidas representativas}
Los siguentes valores pretenden ser representates de todos los datos que se estén analizando.
No tenemos garantís de que realmente lo sean así que para ellos necesitamos de erramientas que nos lo confiermen o desmientan.
\subsubsection{Media Aritmetica}
Suma ponderada por la cantidad de valores sumados.
Se podría haber utilizado la función sum que suma todos los valores de un vector en vez de haber iterado sobre ellos.
<<mediaAritmetica>>=
mediaAritmetica
@
\subsubsection{Media Geométrica}
Raiz de orden igual a la cantidad de valores de la multiplicación de todos ellos.
El logaritmo de la media geométrica también puede expresarse como la media aritmética de los logaritmos de cada dato.
<<mediaGeometrica>>=
mediaGeometrica
@
\subsubsection{Media Armónica}
Inverso de la media de los inversos.
<<mediaArmonica>>=
mediaArmonica
@
\subsubsection{Desviacion Típica}
Nos indica como de buena es la media aritmética. Cuanto menor sea la desviación mejor será la media.
Raiz cuadrada de la varianza.
<<desviacionTipica>>=
desviacionTipica
@
\subsubsection{Desviacion Media}
Nos indica como de buena es la media aritmética. Cuanto menor sea la desviación mejor será la media.
Se suele utilizar la desviacion típica en vez de la desviacion media.
Suma ponderada por la cantidad de valores del valor absoluto de los errores.
Se define error como la resta entre un valor y la media aritmética de todos ellos.
<<desviacionMedia>>=
desviacionMedia
@
\subsubsection{Varianza}
Nos indica como de buena es la media aritmética. Cuanto menor sea la varianza mejor será la media.
Suma ponderada por la cantidad de valores del cuadrado de los errores.
Se define error como la resta entre un valor y la media aritmética de todos ellos.
<<varianza>>=
varianza
@
\subsubsection{Tchebychev}
Decir que la desviación típica es mejor cuanto menor sea no es demasiado precios.
El teorema de tchebychev nos proporciona una representación muy visual del significado de la media.
Se puede entender la media como un valor entorno al que se ubican los datos y la desviacion típica como una circunferencia con centro en la media y radio el valor de la desviación multiplicado por un factor K.
Tchebychev nos proporciona el porcentaje mínimo de valores que estarán dentro de cada valor de radio.
Esto nos ayuda a comparar la desviación obtenida con los datos que tratamos de una forma más significativa.
<<tchebychev>>=
tchebychev
@

\subsection{Medidas de ordenación}
\subsubsection{Mediana}
La mediana la hemos calculado ordenando los datos en orden ascendente 
y obteniendo el punto que se encuentra en la mitad de ese vector 
o la media entre los 2 puntos que se encuentran en este lugar.
<<mediana>>=
mediana
@
\subsubsection{Cuartiles}
Los cuartiles los hemos calculado ordenando los datos en orden ascendente 
y obteniendo los 3 puntos que dividen el vector en 4 partes iguales, es decir, 
el cuartil 25, el 50 y el 75.
<<cuartiles>>=
cuartiles
@
\subsubsection{Cuantil54}
El cuantil 54 los hemos calculado ordenando los datos en orden ascendente 
y obteniendo el punto en el que detrás de él se encuentran el 54% de los datos. 
<<cuantil54>>=
cuantil54
@
\subsubsection{Rango}
Nos dice cual es el valor máximo y mínimo de un conjunto de datos.
<<rango>>=
rango
@

\subsection{Otras funciones}
\subsubsection{Primer contacto con los datos}
Nos proporciona información básica para poder comanzar a trabjar con un conjunto de datos.
Muestra el nombre de las variables y su tipo.
No se pueden analizar los datos si no se puede acceder a las variables que están disponibles para ser analizadas por no conocer ni su nombre.
<<getInfo>>=
getInfo
@
\subsubsection{Visualización}
Hemos creado una función que dibuja una gráfica de la recuencia relativa sobre la que añade líneas verticales 
representando las principales variables estadísticas que manejamos.
Media aritmética, moda, mediana y varianza.
<<plotFrecuencyData>>=
plotFrecuencyData
@
\subsubsection{Crear domuntos .pdf y .tex}
Hemos automatizado este proceso con esta función para hacerlo más sencillo.
<<saveToPdf>>=
saveToPdf
@

\end{document}
